# -*- coding: utf-8 -*-
"""Untitled45.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FdnLs-uU106L0YTlw3OMAfxSTBHA1Wcf
"""

!pip install split-folders

import numpy
import pandas as pd
import matplotlib.pyplot as plt
import os
import splitfolders

from google.colab import drive
drive.mount('/content/drive')

df=pd.read_csv('/content/drive/MyDrive/data/archive (1)/driver_imgs_list.csv')
df.head()

data_dir="/content/drive/MyDrive/data/archive (1)/imgs/train"
splitfolders.ratio(data_dir,output="output",seed=1337,ratio=(.8,.2),group_prefix=None,move=False)

import os
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator

batch_size=32
datagen=ImageDataGenerator(rescale=1/255,
                           zoom_range=0.05,
                           width_shift_range=0.05,
                           height_shift_range=0.05,
                           shear_range=0.05,
                           fill_mode='nearest'
                           )

train=datagen.flow_from_directory('output/train',
                                  target_size=(256,256),
                                  batch_size=batch_size)

val_gen=ImageDataGenerator(rescale=1/255)
val=val_gen.flow_from_directory('output/val',
                               target_size=(256,256),
                               batch_size=batch_size)

for data_batch,labels_batch in train:
    print('data batch shape:',data_batch.shape)
    print('labels batch shape:',labels_batch.shape)
    break

from tensorflow.keras.applications.vgg16 import preprocess_input

batch_size=32
datagen=ImageDataGenerator(preprocessing_function=preprocess_input,
                           zoom_range=0.05,
                           width_shift_range=0.05,
                           height_shift_range=0.05,
                           shear_range=0.05,
                           fill_mode='nearest'
                           )

train=datagen.flow_from_directory('output/train',
                                  target_size=(256,256),
                                  batch_size=batch_size)

val_gen=ImageDataGenerator(preprocessing_function=preprocess_input)
val=val_gen.flow_from_directory('output/val',
                               target_size=(256,256),
                               batch_size=batch_size)

from tensorflow.keras.applications import VGG16

conv_base=VGG16(weights='imagenet',
               include_top=False,
               input_shape=(256,256,3))
conv_base.summary()

from tensorflow.keras import models  # Import models from tensorflow.keras
from tensorflow.keras import layers

model_DL=models.Sequential()
model_DL.add(conv_base)
model_DL.add(layers.Flatten())
model_DL.add(layers.Dense(512,activation='relu'))
model_DL.add(layers.Dropout(0.35))
model_DL.add(layers.Dense(128,activation='relu'))
model_DL.add(layers.Dropout(0.35))
model_DL.add(layers.Dense(32,activation='relu'))
model_DL.add(layers.Dense(11,activation='softmax'))

model_DL.summary()

from tensorflow.keras import models, optimizers

from tensorflow.keras.utils import Sequence

# Ensure that your data generators are properly defined
train = datagen.flow_from_directory('output/train',
                                    target_size=(256, 256),
                                    batch_size=batch_size)

val = val_gen.flow_from_directory('output/val',
                                  target_size=(256, 256),
                                  batch_size=batch_size)

# Compile the model
model_DL.compile(loss='categorical_crossentropy',
                 optimizer=optimizers.Adam(learning_rate=0.0001),
                 metrics=['accuracy'])

# Train the model using the data generators
history = model_DL.fit(train,  # Pass the training data generator
                       epochs=10,
                       validation_data=val)  # Pass the validation data generator

# Plotting training and validation accuracy and loss
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(acc) + 1)

plt.plot(epochs, acc, label='Training accuracy')
plt.plot(epochs, val_acc, label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend()
plt.show()

plt.plot(epochs, loss, label='Training loss')
plt.plot(epochs, val_loss, label='Validation loss')
plt.title('Training and validation loss')
plt.legend()
plt.show()

# Testing and prediction
test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)
test = test_datagen.flow_from_directory('output/test',
                                        classes=['test'],
                                        batch_size=20,
                                        shuffle=False,
                                        target_size=(256, 256),
                                        class_mode=None)

Predict = model_DL.predict(test)

acc=history_DL.history['accuracy']
val_acc=history_DL.history['val_accuracy']
loss=history_DL.history['loss']
val_loss=history_DL.history['val_loss']
epochs=range(1,len(acc)+1)

plt.plot(epochs,acc,label='Training accuracy')
plt.plot(epochs,val_acc,label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend()

loss=history_DL.history['loss']
val_loss=history_DL.history['val_loss']
plt.plot(epochs,loss,label='Training loss')
plt.plot(epochs,val_loss,label='Validation loss')
plt.title('Training and validation loss')
plt.legend()
plt.show()

test_datagen=ImageDataGenerator(preprocessing_function=preprocess_input)
test=test_datagen.flow_from_directory('output/test',
                                  classes=['test'],
                                  batch_size=20,
                                  shuffle=False,
                                  target_size=(256,256),
                                  class_mode=None)

Predict=model_DL.predict(test)